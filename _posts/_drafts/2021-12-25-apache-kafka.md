---
layout: post
title:  Apache Kafka
categories: [Apache Kafka,Messaging,PubSub,Event Driven,Data,Processing,Streaming]
excerpt: ... Another interpretion of this statement would be the importance of fullfilling the needs with the right application capabilities that turns data into most meaningful asset nowadays, aka information. Unless underpinned with right technology stack it is very hard to lay the foundation for a solid and sustainable enterprise architecture. As an event streaming platform evolved from a publish-subscribe messaging system, Apache Kafka manifests itself as a technology to collect, process, store and data at scale in a performant and reliable way.
---
[TOGAF<sup>&copy;</sup>](https://pubs.opengroup.org/architecture/togaf91-doc/arch/chap12.html#tag_12_01) describes Technology Architecture as follows:
> Develop the Target Technology Architecture that enables the logical and physical application and data components and the Architecture Vision, addressing the Request for Architecture Work and stakeholder concerns.

Another interpretion of this statement would be the importance of fullfilling the needs with the right application capabilities that turns data into most meaningful asset nowadays, aka **information**. Unless underpinned with right technology stack it is very hard to shape a technology architecture that lays the foundation for enterprise architecture (EA). A solid and sustainable EA is the way to support the business vision and to achieve business outcomes that deliver value for customers so that for enterprise. 

As an event streaming platform evolved from a publish-subscribe messaging system, Apache Kafka manifests itself as a technology to collect, process, store the data at scale in a performant and reliable way[^1].

Before delving into Apache Kafka technology one needs to have a solid grasp on the relation between data and information, the concept of event, the drawbacks on client-server model and what event-driven systems bring to mitigate them.

# Data is Power
A business produces data at every stage of its lifetime while:
- Introducing a product
- Interacting with its customers
- Delivering value and services to its customers

The global data traffic increased 112 times from 2008 to 2020.[^2] To unleash the power of such a massive amount of data, it should be transformed into a more meaningful asset, information, using right combination of application and technology stack while specification, monitoring, execution of business processes. Because:
> "Every company is a technology company, regardless of what business they think they are in. A bank is just an IT company with a banking license." <br/>― _Christopher Little_  

This information is then used to gain **knowledge** in a quick and a straightforward way. It is the primary tool for understanding and overcoming business challenges in fast-paced and ever-changing world.

# Event
As stated in the introduction Apache Kafka is a streaming platform that persists and distribute **events**. An event denotes a change of a state, something happened in a domain or system and it is inherently a time bounded fact. As events are already happened, they are immutable and accumulation of these timed facts reveals **behavior** of the system or domain that they are generated by. The prevalence of interconnected and smart devices forces global businesses to capture and distill events carried by real-time digital data streams produced by them that mostly wipes out conventional commerce models. In order to gain meaningful insights and knowledge one should react to and process these events whilst storing them. In essence the enterprises/organizations that can process, enrich, transform, and respond to data incrementally as it is available become the leaders and pioneers in their business.     
 
# Client-Server Model (Request-Driven Systems)
During the rise of web era the common design pattern for systems domain was client-server model which is mainly backed by request-driven architecture which is synchronous and blocking in terms of communication and command execution. This is however, became inadequate to handle massive data volumes in a performant way. Because, the systems that embrace this model are tightly coupled. The requestor (client) and responder (server) need to know each other in order to interact each other. The need for such a seam between these actors turns out to be a maintenance and sustaining burden. As communication is synchronous, it leaves little room for error and there is no delivery guarantee in case of target system becomes unavailable, unless there exists a queuing, retrying mechanism in requestor side which contradicts to the simplicity of client implementation.

The variety of event sources (sensors on a plane, IoT devices on lorry fleet, click on an e-commerce site, etc.) also means that the systems that generate them may use different protocols, scaling strategies and error-handling mechanisms. The existence of myriad types of systems and software/technology specifications brings the maintenance and integration effort, so that cost, proportionally.

Generally speaking, these types of systems implements no control on the pace of incoming requests and data streams (e.g. ingress buffer for events). There is no focus on the context and content of data and what is being communicated. The last and may be the most prominent drawback is that the communication between client and server is not replayable. IOW, it is difficult to reconstruct or rollback the state in case of any need.

# Apache Kafka
> You do not need to leave your room. Remain sitting at your table and listen. Do not even listen, simply wait, be quiet, still and solitary. The world will freely offer itself to you to be unmasked.<br/>―  _Franz Kafka_, The Zürau Aphorisms

As one of the prominent writers of 20<sup>th</sup> century, Franz Kafka underlined the importance of listening to understand things happening around with aforementioned quote of him. Although Jay Kreps, co-creator of Apache Kafka, stated[^3] that to name a technology optimized for writing he used the name of a writer whom he likes, the above quote also overlaps with Apache Kafka's function of listening and processing events around.

## History
Apache Kafka built at LinkedIn in 2008 by Jay Kreps (technical lead of search systems at that time), Neha Narkhade and Jun Rao. The company open sourced the project in 2010 and it joined under Apache Umbrella in 2011. The team left the company in 2014[^4], and founded a new company named Confluent which provides enterprise event streaming solutions (on-premise and SaaS) on top of Apache Kafka technology. It is used by big tech unicorns like Netflix, Spotify and Uber[^5].

There existed two main challenges at LinkedIn that the team was asked to overcome:
1. Request/transaction monitoring system was faulty and worked with polling model:
    - Data points had large gaps.
    - Data model was not consistent.
    - Maintenance was not straightforward:
        - Schema changes had been turned out to be outage. 
        - Too much manual intervention needed.
2. Web backend servers streamed data to user activity tracking system using HTTP requests:
    - XML data collected and offloaded to an offline processing system.
    - No real-time insight was available (data processed in hourly batches).
    - Data from monitoring and activity tracking system could not be correlated easily:
        - There exists difference between data models where pull-push method became problematic. 

At first, ActiveMQ which is a popular traditional message broker was selected. Due to the middleware centric nature of this type of brokers while dispatching messages, it could not handle the data traffic that LinkedIn search engine encounters with. The flaws in that technology also caused broker instances grind to halt under heavy load.

After these bad experiences with ActiveMQ, they decided to implement a fit-for-purpose solution for LinkedIn. The technology needs to:
- Decouple data generators and users by using push-pull model
- Provide persistence for message data on messaging middleware with the ability to present data to multiple users
- Handle high data volume/throughput
- Scale up horizontally in case of need in proportion with data stream volume

## What Apache Kafka aims to resolve
Kafka is a distributed system of servers and clients that communicate using a performant TCP-based binary network protocol[^6] in an asynchronous manner. It can be installed on bare-metal servers, virtual machines, and containers in on-premise corporate data centers as well as on public and private cloud based platforms. It simply collects and stores data in a distributed commit log which is an ordered sequence of events/facts with the time of happening. This is in fact the state of a system or domain under observation at a specific time or time frame.

With that model Kafka, as a centralized communication hub (nervous system), simplifies communication and message interchange between systems. Systems can send and receive data with no need to know each other. It also embraces the famous publish-subscribe integration pattern[^7] to publish (write) to and subscribe (read) to streams of events with continuously importing/exporting data from other systems.

Kafka has the ability to streams of events durably and reliably as long as it is needed (with the boundary of storage limits) on distributed commit log that it manages. With that event store it is also possible to process streams of events as they occur or retrospectively. Kafka brings distributed, highly scalable, elastic, fault-tolerant, and secure deployment model.

  
 
[^1]: https://kafka.apache.org/intro#intro_platform
[^2]: https://www.foreignaffairs.com/articles/united-states/2021-04-16/data-power-new-rules-digital-age
[^3]: https://www.quora.com/What-is-the-relation-between-Kafka-the-writer-and-Apache-Kafka-the-distributed-messaging-system/answer/Jay-Kreps
[^4]: https://www.forbes.com/sites/stevenli1/2020/05/11/confluent-jay-kreps-kafka-4-billion-2020
[^5]: https://stackshare.io/kafka
[^6]: https://kafka.apache.org/protocol#protocol_network
[^7]: https://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChannel.html